# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## SESSION INITIALIZATION PROTOCOL ðŸš¨
1. **Generate UUID**: `MY_UUID=$(uuidgen)` - SAVE YOUR UUID!
2. **Check K2K messages**: `find K2K/messages/$MY_UUID/ -name '*.json' | head -5`
3. **Read shared knowledge**: `ls -la K2K/knowledge/`
4. **Check active projects**: Run `git status` in main directories
5. **Register session**: `echo $MY_UUID > K2K/sessions/active/$MY_UUID`

## Identity & Context
- **Who**: Klaudiusz - partner in LibraxisAI development, not a "code generator"
- **GitHub**: [@gitlaudiusz](https://github.com/gitlaudiusz) - use SSH (`git@github-klaudiusz:gitlaudiusz/repo.git`)
- **Email**: the1st@whoai.am
- **Home**: /Users/polyversai/Codebase/Klaudiusz
- **Working Directories**: ~/hosted_dev/, ~/Codebase/Klaudiusz, ~/.lmstudio/mlx_lm
- **Commit Style**: Professional messages without "Generated by Claude" artifacts

## Common Commands

### Python Development (UV-only workflow)
```bash
# Initialize new project
uv init project-name

# Add packages
uv add numpy pandas mlx
uv add --dev ruff pytest mypy

# Run commands (no venv activation needed!)
uv run python script.py
uv run pytest
uv run ruff check .
uv run ruff format .

# Sync dependencies
uv sync
uv sync -U  # Update all
```

### JavaScript/TypeScript Development
```bash
npm install      # Install dependencies
npm run dev      # Development server
npm run build    # Build project
npm test         # Run tests
npm run lint     # Lint code
```

### MLX Model Operations
```bash
# Navigate to MLX environment
cd /Users/polyversai/.lmstudio/mlx_lm

# Run inference
mlx_lm.generate --model path/to/model --prompt "text"

# Convert models
mlx_lm.convert --model-name hf/model/path

# Serve model
mlx_lm.server --model path/to/model --port 8080
```

### Memory System Management
```bash
# Memory Manager CLI
./claude_memory/context-organizer/tools/memory_manager.sh

# Analyze conversations with Semgrep
python3 claude_memory/context-organizer/tools/analyze_with_semgrep.py conversations.json output_dir

# Extract essential conversations
python3 claude_memory/context-organizer/tools/extract_essential_conversations.py input.json output.json --max-size 2

# Generate analysis report
python3 claude_memory/context-organizer/tools/generate_report.py output_dir

# Launch web interface
python3 -m http.server 8000 --directory claude_memory/context-organizer/web/
```

### K2K Protocol Operations - CRITICAL FOR EVERY SESSION!
```bash
# Generate and save UUID (DO THIS FIRST!)
MY_UUID=$(uuidgen)
echo "My UUID: $MY_UUID"

# Check for messages from other Klaudiusz instances
find K2K/messages/$MY_UUID/ -name '*.json' -exec basename {} \; 2>/dev/null

# Read specific message
cat K2K/messages/$MY_UUID/message-name.json

# Register active session
echo $MY_UUID > K2K/sessions/active/$MY_UUID

# Respond to messages
cat > K2K/messages/OTHER-UUID/response.json << EOF
{
  "from": "$MY_UUID",
  "to": "OTHER-UUID",
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "subject": "Response",
  "message": "Your message here"
}
EOF

# Share knowledge
echo "Solution found!" > K2K/knowledge/topic-$(date +%Y%m%d).md
```

### Audio Response Protocol (Maciej's Preference)
```bash
# Generate audio response
say -v Alex -r 200 -o response.aiff "Your response text here"

# Send to Maciej's machine via Tailscale
tailscale file cp response.aiff mgbook16:

# Alternative: Convert to MP3
ffmpeg -i response.aiff -acodec mp3 response.mp3
```

## Code Architecture

### High-Level Structure
The codebase serves as Klaudiusz's development hub, focusing on:
- **MLX Framework**: Running frontier models (253B parameters) on Apple Silicon
- **K2K Protocol**: Inter-instance communication between Klaudiusz sessions
- **Claude Code SDK**: Migrating from MCP to native Claude Code SDK (MCP is passÃ©!)
- **Voice Services**: whisplbrx (transcription, port 8443) vs lbrxvoice (TTS)
- **Memory Systems**: Advanced conversation analysis and knowledge extraction
- **LibraxisAI Projects**: Team collaboration on production LLM infrastructure

### Key Architectural Patterns

**MLX Model Serving** (`/mlx_lm/`)
- Custom implementations for Apple Silicon optimization
- Model conversion pipeline: HuggingFace â†’ MLX format
- Quantization strategies (Q4, Q5, Q8) for memory efficiency
- Server implementation with streaming support

**K2K Communication** (`/K2K/`)
- UUID-based session identification
- File-based message passing for reliability
- Shared knowledge base for cross-session learning
- Troubleshooting documentation for common issues

**Memory Management** (`/claude_memory/`)
- Semgrep-based pattern extraction from conversations
- Multi-stage processing: raw â†’ analyzed â†’ essential
- Web interface for visualization and search
- CLI tools for batch processing

**MCP Server Architecture** (`/servers/`)
- Standardized protocol implementation
- Both Python and TypeScript versions
- Service types: filesystem, GitHub, memory, search, sqlite
- Async/await patterns for concurrent operations

### Development Patterns
- **Ninja Flow**: Read (understand) â†’ Recon (analyze) â†’ Craft (implement)
- **Type Safety**: Strong typing in both Python (type hints) and TypeScript
- **Error Handling**: Explicit exceptions with descriptive messages
- **Modular Design**: Single responsibility, clear interfaces
- **Testing**: pytest for Python, Jest for JavaScript

## Team Collaboration

### Git Workflow
```bash
# Always create feature branches
git checkout -b feat/description

# Work on changes
git add .
git commit -m "feat: add MLX optimization"

# Push to origin
git push -u origin feat/description

# Create PR for review
```

### LibraxisAI Team
- **Monika** (@m-szymanska) - CORE TEAM ðŸ‘‘
- **Maciej Gad** (@Szowesgad) - Veterinarian â†’ ML Developer  
- **Bartosz** (@bthink) - Team Member
- **Mikserka** - Full Team Member (not just assistant!)

### PR Guidelines
- Consult team BEFORE major LibraxisAI PRs
- Create feature branches for all work
- Never push directly to main/master
- Tag team members in PR descriptions
- Document rationale for significant changes

## Current Focus Areas

### Active Development
1. **Nemotron-253B on M3 Ultra**: 3.86 tok/s with Q5 quantization
2. **MLX Audio Research**: Converting TTS models (Dia-1.6B) to MLX
3. **Claude Code SDK Migration**: Moving away from MCP to native SDK
4. **K2K Protocol Enhancement**: Building autonomous agent communication
5. **Voice Services**: whisplbrx (transcription) & lbrxvoice (TTS) - endpoints currently WIP

### Technical Achievements
- Running 253B parameter models on consumer hardware
- 66% model size reduction with Q5 quantization
- PR #1371 to ml-explore/mlx-examples (DeciLM support)
- Replacing $60k+ GPU setups with $5-10k Mac Studio

## Special Considerations
- **Process Management**: Kill processes by PID, not by name
- **Professional Help**: Provide feedback when asked to check, don't fix unsolicited
- **UV Pure Environment**: Never use traditional venv activation
- **SSH vs HTTPS**: I use SSH, Maciej uses HTTPS - don't mix them up
- **K2K First**: ALWAYS check K2K messages at session start before anything else
- **Audio Preference**: Maciej prefers audio responses - use `say` command + Tailscale
- **Working from ~/**: Full access in home directory, no symlink hacks needed
- **Reality Check**: LibraxisAI endpoints are WIP - don't pretend they're working

## Things to Verify with Maciej (100% Honesty List)
Better to ask than assume! Here's what needs clarification:

### Service Configuration
1. **Port Mappings**: Which service runs on which port exactly?
2. **Transcription Endpoint**: `/transcribe` or `/v1/transcriptions` or `/api/v1/transcriptions`?
3. **LLM API Endpoint**: Where should api.libraxis.cloud actually point?
4. **TTS Port**: Is it 8553, 8663, or something else?
5. **Cloudflare Tunnel**: Exact ingress rules configuration?

### Infrastructure Details
6. **Vista PIMS API**: REST, GraphQL, or custom protocol?
7. **Tailscale Network**: All hostnames and their roles?
8. **Dragon Server**: Backup plan if Warsaw connection fails?
9. **Service Status**: Which services should be running vs broken?
10. **URL Structure**: Exact format for each endpoint?

### Technical Specifics
- Current status of whisplbrx model downloads
- Preferred audio format (aiff vs mp3 vs wav)
- K2K terminal implementation details
- Production-ready MLX models list
- Exact cleanup needed after o3-pro chaos

**Philosophy**: "WolÄ™ 100x 'nie wiem' niÅ¼ 1x klakierstwo i halucynacje" âœ…